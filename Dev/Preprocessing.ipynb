{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses several Python modules to handle tasks such as image processing, data manipulation, deep learning, and visualization. These dependencies can be installed using pip if they are not already available in your environment with the Following formula :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python pandas pillow torch torchvision matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meaninful areas of the captchas\n",
    "The input data consists of CAPTCHAs saved as PNG files. These CAPTCHAs have dimensions of 340 x 410 pixels, but not all pixels are relevant for our solver. Only the central field and the two drawings in the top-right corners are essential for solving.  \n",
    "\n",
    "This section of the notebook focuses on isolating these meaningful areas and adjusting the labels accordingly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is splitting the captchas and extracs the field (where the user has to click for solving the captcha) and the 2 draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def crop_and_save_images(input_folder, output_folder,top_pixels, bot_pixels, left_pixels, right_pixels):\n",
    "    \"\"\"\n",
    "    Crops images in the input_folder according to predefined pixel boundaries\n",
    "    and saves them to the output_folder with the same filenames.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing the original images.\n",
    "        output_folder (str): Path where the cropped images will be saved.\n",
    "    \"\"\"\n",
    " \n",
    "    # Create output folder if it does not exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Process each image in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Read the image\n",
    "        image = cv2.imread(input_path)\n",
    "        if image is None:\n",
    "            print(f\"Skipping {filename} (could not load image)\")\n",
    "            continue\n",
    "\n",
    "        # Apply cropping\n",
    "        cropped_image = image[bot_pixels:top_pixels, left_pixels:right_pixels]\n",
    "\n",
    "        # Save the cropped image to the new folder\n",
    "        cv2.imwrite(output_path, cropped_image)\n",
    "\n",
    "\n",
    "\n",
    "# Ectract interesting zone\n",
    "def isolate_information_zones(captchas_folder = \"your_captchas/captchas\", field_folder = \"your_captchas/field\", draw1_folder = \"your_captchas/draw1\", draw2_folder = \"your_captchas/draw2\"):\n",
    "    #Extract the field where the user have to click\n",
    "    print(\"Extracting fields...\")\n",
    "    \n",
    "    top_pixels,bot_pixels,left_pixels,right_pixels = 310,100,65,275 # Field coordonates\n",
    "    crop_and_save_images(captchas_folder,field_folder,top_pixels,bot_pixels,left_pixels,right_pixels) #Field\n",
    "    print(\"Field extracted\")\n",
    "\n",
    "    #Extract the first draw (left one)\n",
    "    print(\"Extracting draws...\")\n",
    "    \n",
    "    top_pixels,bot_pixels,left_pixels,right_pixels = 55,5,185,235 # Draw 1 coordonates\n",
    "    crop_and_save_images(captchas_folder,draw1_folder,top_pixels,bot_pixels,left_pixels,right_pixels) #Draw 1\n",
    "    print(\"Draw 1 extracted\")\n",
    "\n",
    "    #Extract the second draw (right one)\n",
    "    top_pixels, bot_pixels, left_pixels, right_pixels = 55,5, 260, 310 # Draw 2 coordonates\n",
    "    crop_and_save_images(captchas_folder,draw2_folder,top_pixels,bot_pixels,left_pixels,right_pixels) #Draw 2\n",
    "    print(\"Draw 2 extracted\")\n",
    "    print(\"All images extracted\")\n",
    "\n",
    "#Example set\n",
    "imgs_folder = \"your_captchas/\" \n",
    "captchas_folder = imgs_folder + \"captchas\"\n",
    "field_folder = imgs_folder +\"field\"\n",
    "draw1_folder = imgs_folder +\"draw1\"\n",
    "draw2_folder = imgs_folder +\"draw2\"\n",
    "isolate_information_zones(captchas_folder=captchas_folder, field_folder=field_folder,draw1_folder=draw1_folder,draw2_folder=draw2_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell adapts the labels file to the truncated fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def adjust_x_coordinates(label, left_pixels):\n",
    "    \"\"\"\n",
    "    Adjusts the x-coordinate by subtracting a left offset.\n",
    "\n",
    "    Args:\n",
    "        label (float): The original x-coordinate.\n",
    "        left_pixels (int): The number of pixels to subtract from the x-coordinate.\n",
    "\n",
    "    Returns:\n",
    "        float: The adjusted x-coordinate.\n",
    "    \"\"\"\n",
    "    return label - left_pixels\n",
    "\n",
    "def adjust_y_coordinates(label, bot_pixels):\n",
    "    \"\"\"\n",
    "    Adjusts the y-coordinate by subtracting a bottom offset.\n",
    "\n",
    "    Args:\n",
    "        label (float): The original y-coordinate.\n",
    "        bot_pixels (int): The number of pixels to subtract from the y-coordinate.\n",
    "\n",
    "    Returns:\n",
    "        float: The adjusted y-coordinate.\n",
    "    \"\"\"\n",
    "    return label - bot_pixels\n",
    "\n",
    "def truncate_labels(df, left_pixels=65, bot_pixels=100):\n",
    "    \"\"\"\n",
    "    Adjusts the coordinate labels in a DataFrame by subtracting fixed offsets. \n",
    "    \n",
    "    The DataFrame is expected to have the columns \"x1\", \"y1\", \"x2\", and \"y2\".\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the labels.\n",
    "        left_pixels (int, optional): Number of pixels to subtract from x-coordinates. Default is 65.\n",
    "        bot_pixels (int, optional): Number of pixels to subtract from y-coordinates. Default is 100.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the adjusted labels.\n",
    "    \"\"\"\n",
    "    # Ensure coordinate columns are numeric.\n",
    "    df[['x1', 'y1', 'x2', 'y2']] = df[['x1', 'y1', 'x2', 'y2']].apply(pd.to_numeric)\n",
    "    \n",
    "    # Adjust the x-coordinates by subtracting left_pixels.\n",
    "    df['x1'] = df['x1'].apply(lambda x: adjust_x_coordinates(x, left_pixels))\n",
    "    df['x2'] = df['x2'].apply(lambda x: adjust_x_coordinates(x, left_pixels))\n",
    "    \n",
    "    # Adjust the y-coordinates by subtracting bot_pixels.\n",
    "    df['y1'] = df['y1'].apply(lambda y: adjust_y_coordinates(y, bot_pixels))\n",
    "    df['y2'] = df['y2'].apply(lambda y: adjust_y_coordinates(y, bot_pixels))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_labels_file(input_csv=\"labels.txt\", output_csv=\"truncated_labels.csv\", left_pixels=65, bot_pixels=100):\n",
    "    \"\"\"\n",
    "    Processes a labels CSV file by adjusting the coordinates with fixed offsets and saves the result.\n",
    "    \n",
    "    This function reads the input CSV (which should contain columns \"img_name\", \"x1\", \"y1\", \"x2\", \"y2\"),\n",
    "    adjusts the coordinate values by subtracting the provided offsets, and then writes the adjusted\n",
    "    DataFrame to a new CSV file. The img_name column is expected to be ordered by lexicographic order.\n",
    "    \n",
    "    Args:\n",
    "        input_csv (str): Path to the input labels CSV file.\n",
    "        output_csv (str): Path where the adjusted labels CSV will be saved.\n",
    "        left_pixels (int, optional): Number of pixels to subtract from x-coordinates. Default is 65.\n",
    "        bot_pixels (int, optional): Number of pixels to subtract from y-coordinates. Default is 100.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The processed DataFrame containing adjusted labels.\n",
    "    \"\"\"\n",
    "    # Load the labels CSV file.\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Adjust the labels using the truncate_labels function.\n",
    "    df_adjusted = truncate_labels(df, left_pixels, bot_pixels)\n",
    "    \n",
    "    # Save the adjusted labels to the output CSV file.\n",
    "    df_adjusted.to_csv(output_csv, index=False)\n",
    "    \n",
    "    return df_adjusted\n",
    "\n",
    "labels_path = \"labels.txt\"\n",
    "truncate_labels_path = \"truncated_labels.csv\"\n",
    "processed_df = process_labels_file(labels_path,truncate_labels_path, left_pixels=65, bot_pixels=100) #The left and bot pixels are the ones used to isolate the field\n",
    "print(\"Processed labels saved to truncated_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation  \n",
    "\n",
    "Due to the limited amount of data available, we will apply data augmentation techniques to expand our dataset. Our goal is to develop a model that, given a field and a drawing, can accurately determine the coordinates of the drawing within the field.  \n",
    "\n",
    "To achieve this, we will rotate each drawing three times. Since each CAPTCHA contains two drawings, this process effectively increases the number of training samples by a factor of 8 compared to a naive training approach that simply uses full CAPTCHAs with all labels.  \n",
    "\n",
    "When performing data augmentation, it is crucial to prevent data leakage between the evaluation and training sets. To ensure a fair evaluation, we will carefully separate the train and evaluation datasets in the following cells.  \n",
    "\n",
    "The following cell is creating the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "\n",
    "###############################################\n",
    "# Augmentation Functions\n",
    "###############################################\n",
    "\n",
    "def rotate_image(image_path, num_rotations=4, output_dir=\"augmented_images\", rotate=True):\n",
    "    \"\"\"\n",
    "    Rotates an image 90° num_rotations times and saves each rotated version.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the original image.\n",
    "        num_rotations (int): Number of 90° rotations to apply.\n",
    "        output_dir (str): Directory to save the rotated images.\n",
    "        rotate (bool): If True, perform rotation; otherwise, skip rotation.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of file paths to the saved rotated images.\n",
    "    \"\"\"\n",
    "    # Load the image using PIL\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    rotated_image_paths = []\n",
    "    # Rotate the image the specified number of times\n",
    "    for i in range(num_rotations):\n",
    "        # Rotate image only if rotate flag is True\n",
    "        if rotate:\n",
    "            # Rotate 90 degrees (clockwise) and expand image to avoid cropping\n",
    "            img = img.rotate(90, expand=True)\n",
    "        # Create a new filename for the rotated image.\n",
    "        # Note: We create one filename per rotation, not in an inner loop.\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        rotated_image_path = os.path.join(output_dir, f\"{base_name}_rotated_{i+1}.png\")\n",
    "        # Save the rotated image\n",
    "        img.save(rotated_image_path)\n",
    "        rotated_image_paths.append(rotated_image_path)\n",
    "    \n",
    "    return rotated_image_paths\n",
    "\n",
    "###############################################\n",
    "# Dataset Generation Functions\n",
    "###############################################\n",
    "\n",
    "def count_png_images(folder_path):\n",
    "    \"\"\"\n",
    "    Counts the number of PNG images in a given folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of PNG images in the folder.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise ValueError(f\"Invalid folder path: {folder_path}\")\n",
    "    # Count files ending with '.png' (case insensitive)\n",
    "    png_count = sum(1 for file in os.listdir(folder_path) if file.lower().endswith(\".png\"))\n",
    "    return png_count\n",
    "\n",
    "def get_treshold(folder_path, train_test_split=0.8):\n",
    "    \"\"\"\n",
    "    Computes a threshold index based on the train_test_split ratio.\n",
    "    This threshold is used to split the data into training and test subsets.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Folder containing images.\n",
    "        train_test_split (float): Fraction of data to be used for training.\n",
    "\n",
    "    Returns:\n",
    "        int: The threshold index.\n",
    "    \"\"\"\n",
    "    # Subtract a tiny epsilon to avoid floating point rounding issues\n",
    "    return int(train_test_split * count_png_images(folder_path) - 0.000001) + 1\n",
    "\n",
    "def gen_augmented_images(image_folder, treshold, output_final_dir, output_dir=\"training/\", rotate=True):\n",
    "    \"\"\"\n",
    "    Generates augmented (rotated) images from the provided image folder.\n",
    "    Splits the generated images into training and testing based on the threshold.\n",
    "\n",
    "    Args:\n",
    "        image_folder (str): Folder containing the original images.\n",
    "        treshold (int): Number of images to include in the training set.\n",
    "        output_final_dir (str): Subfolder name for saving the augmented images.\n",
    "        output_dir (str): Base output directory (default is \"training/\").\n",
    "        rotate (bool): Whether to apply rotation.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # Process images for the training set\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if count >= treshold:\n",
    "            break\n",
    "        count += 1\n",
    "        # Build full path and generate augmented images in train_set folder\n",
    "        full_input_path = os.path.join(image_folder, filename)\n",
    "        output_path = os.path.join(output_dir, \"train_set\", output_final_dir)\n",
    "        rotate_image(full_input_path, output_dir=output_path, rotate=rotate)\n",
    "    \n",
    "    # Reset counter for test set processing\n",
    "    count = 0\n",
    "    # Process images for the test set (skip training images)\n",
    "    for filename in os.listdir(image_folder):\n",
    "        count += 1\n",
    "        if count <= treshold:\n",
    "            continue\n",
    "        full_input_path = os.path.join(image_folder, filename)\n",
    "        output_path = os.path.join(output_dir, \"test_set\", output_final_dir)\n",
    "        rotate_image(full_input_path, output_dir=output_path, rotate=rotate)\n",
    "\n",
    "def gen_datasets(imgs_folder='your_captchas/', train_test_split=0.8):\n",
    "    \"\"\"\n",
    "    Generates augmented datasets for field images, draw1 images, and draw2 images.\n",
    "    It uses a given train/test split to determine which images are used for training and testing.\n",
    "\n",
    "    Args:\n",
    "        imgs_folder (str): Folder containing subfolders 'field/', 'draw1/', and 'draw2/'.\n",
    "        train_test_split (float): Fraction of data to be used for training.\n",
    "    \"\"\"\n",
    "    # Process field images\n",
    "    field_folder = os.path.join(imgs_folder, \"field/\")\n",
    "    treshold = get_treshold(field_folder, train_test_split=train_test_split)\n",
    "    gen_augmented_images(field_folder, treshold=treshold, output_final_dir=\"field/\", rotate=False)\n",
    "\n",
    "    # Process draw1 images (apply rotation)\n",
    "    draw1_folder = os.path.join(imgs_folder, \"draw1/\")\n",
    "    gen_augmented_images(draw1_folder, treshold=treshold, output_final_dir=\"rotated_draw1/\", rotate=True)\n",
    "\n",
    "    # Process draw2 images (apply rotation)\n",
    "    draw2_folder = os.path.join(imgs_folder, \"draw2/\")\n",
    "    gen_augmented_images(draw2_folder, treshold=treshold, output_final_dir=\"rotated_draw2/\", rotate=True)\n",
    "\n",
    "    print(\"Augmentation and dataset generation done!\")\n",
    "\n",
    "###############################################\n",
    "# Main execution\n",
    "###############################################\n",
    "\n",
    "# Set your images folder and train-test split ratio\n",
    "imgs_folder = 'your_captchas/'\n",
    "train_test_split = 0.8\n",
    "\n",
    "# Generate augmented datasets\n",
    "gen_datasets(imgs_folder=imgs_folder, train_test_split=train_test_split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell moves the augmented labels file to the appropriate folder in preparation for dataset creation in the `Training.ipynb` notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "def augmentation(df: pd.DataFrame, noise_amplitude = 3, field_size = 210) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create augmented dataframe by adding the name of the rotated images and noise to the coordonates. \n",
    "    \"\"\"\n",
    "\n",
    "    augmented_data = []  # List to collect all rows for the new dataframe\n",
    "    for _, row in df.iterrows():  # iterrows returns index and row (row is a pandas Series)\n",
    "        for i in range(1, 5):  # Iterate through 1 to 4 for the rotations\n",
    "            # Create the new img_name for each rotated image\n",
    "           \n",
    "            img_name = f'{row[\"img_name\"][:-4]}_rotated_{i}.png'\n",
    "            # Create a new row with the same coordinates but updated image name with noise\n",
    "            new_row = {\n",
    "                df.columns[0]: img_name,\n",
    "                df.columns[1]: (row[df.columns[1]] + noise_amplitude*(1/2-random.random()))/field_size,\n",
    "                df.columns[2]: (row[df.columns[2]] + noise_amplitude*(1/2-random.random()))/field_size,\n",
    "                df.columns[3]: (row[df.columns[3]] + noise_amplitude*(1/2-random.random()))/field_size,\n",
    "                df.columns[4]: (row[df.columns[4]] + noise_amplitude*(1/2-random.random()))/field_size\n",
    "            }\n",
    "            \n",
    "            # Append the new row to the augmented_data list\n",
    "            augmented_data.append(new_row)\n",
    "\n",
    "    # Convert the list of new rows to a DataFrame\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "    \n",
    "    return augmented_df\n",
    "\n",
    "def save_csv_for_training(df,draw=1,train_test_split=0.8):\n",
    "    \"\"\"\n",
    "    Saves the csv containing the labels in the appropriate folder for the training and evaluating datasets\n",
    "\n",
    "    Args:\n",
    "        df (pd.Dataframe): Dataframe containing the augmented dataframe containing this columns [\"img_name\", \"x1\", \"y1\", \"x2\", \"y2\"]\n",
    "        draw (int): 1 or 2 to chose the coordonate to remove\n",
    "        train_test_split (float) : The proportion of images for the training\n",
    "    \"\"\"\n",
    "    L = [1,2]\n",
    "    df = df.drop([f\"x{L[-draw]}\",f\"y{L[-draw]}\"],axis=1)\n",
    "    df.columns = [\"img_name\",\"x\",\"y\"]\n",
    "    treshold = get_treshold(field_folder,train_test_split) * 4 # treshold * 4 because the augmented dataframe has 4 rows for each image\n",
    "    df[treshold:].to_csv(f\"training/test_set/rotated_draw{draw}/augmented_labels.csv\", index= False)\n",
    "    df[:treshold].to_csv(f\"training/train_set/rotated_draw{draw}/augmented_labels.csv\", index= False)\n",
    "\n",
    "\n",
    "#Main pipeline with the csv file in entrance and saving the augmented csv file in output file\n",
    "def labels_augmentation(truncated_labels_path = \"truncated_labels.csv\"):\n",
    "    # Load the original dataframe\n",
    "    df = pd.read_csv(truncated_labels_path)\n",
    "\n",
    "    # Apply augmentation to the dataframe\n",
    "    augmented_df = augmentation(df)\n",
    "\n",
    "    # Save data and normalize for training\n",
    "    save_csv_for_training(augmented_df,draw=1)\n",
    "    save_csv_for_training(augmented_df,draw=2)\n",
    "\n",
    "    # Optionally, save the new augmented dataframe to a CSV\n",
    "    augmented_df.to_csv(\"training/augmented_labels.csv\", index=False)\n",
    "    print(\"Done ! Your labels should be between 0 and 1\")\n",
    "    return augmented_df\n",
    "\n",
    "truncated_labels_path = \"truncated_labels.csv\"\n",
    "labels_augmentation(truncated_labels_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
