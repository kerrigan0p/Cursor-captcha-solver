{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "TEBgRGBSAaeW",
        "outputId": "19bcdec8-4fbf-4374-cd69-a04f06f875d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground truth coordinates: x1=105, y1=175, x2=180, y2=207\n",
            "Ground truth coordinates: x1=40, y1=75, x2=115, y2=107\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def draw_labels_on_image(image_path, labels_file):\n",
        "    \"\"\"\n",
        "    Loads an image from image_path, retrieves ground truth (x1, y1, x2, y2) from labels.txt,\n",
        "    and displays the image with red circles at those coordinates.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image.\n",
        "        labels_file (str): Path to the labels file (CSV or TXT with x1, y1, x2, y2).\n",
        "    \"\"\"\n",
        "    # Load the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Unable to load image: {image_path}\")\n",
        "        return\n",
        "\n",
        "    # Resize the image to (width=340, height=410) to match the model's expected size\n",
        "    image_resized = image#cv2.resize(image, (340, 410))\n",
        "\n",
        "    # Read labels from the file\n",
        "    labels_df = pd.read_csv(labels_file)  # Ensure labels.txt is formatted correctly\n",
        "    image_name = image_path.split('/')[-1]  # Extract filename from path\n",
        "\n",
        "    # Find the row corresponding to the image name (assuming there is an 'id' or filename column)\n",
        "    if 'img_name' in labels_df.columns:\n",
        "        row = labels_df[labels_df['img_name'] == image_name]\n",
        "    else:\n",
        "        row = labels_df.iloc[0]  # If there's no ID column, just use the first row (for testing)\n",
        "\n",
        "    if row.empty:\n",
        "        print(f\"No labels found for {image_name}\")\n",
        "        return\n",
        "\n",
        "    # Extract ground truth coordinates\n",
        "    x1, y1, x2, y2 = row[['x1', 'y1', 'x2', 'y2']].to_numpy().flatten()\n",
        "    x1 = int(x1)\n",
        "    x2 = int(x2)\n",
        "    y1 = int(y1)\n",
        "    y2 = int(y2)\n",
        "    print(f\"Ground truth coordinates: x1={x1}, y1={y1}, x2={x2}, y2={y2}\")\n",
        "\n",
        "    # Draw red circles at the ground truth coordinates\n",
        "    image_drawn = image_resized.copy()\n",
        "    cv2.circle(image_drawn, (x1, y1), radius=5, color=(0, 255, 0), thickness=-1)  # Green circle\n",
        "    cv2.circle(image_drawn, (x2, y2), radius=5, color=(0, 0, 255), thickness=-1)  # Red circle\n",
        "\n",
        "    # Display the image with the drawn points\n",
        "    cv2.imshow(\"img\",image_drawn)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "extract_dir = 'extracted_captchas'\n",
        "processed_images_dir = \"processed_captchas\"\n",
        "image_path = f\"{extract_dir}/captchas_saved/captcha_8.png\"\n",
        "labels_file = \"labels.txt\"\n",
        "draw_labels_on_image(image_path,labels_file)\n",
        "image_path = f\"truncated_captchas/captcha_8.png\"\n",
        "labels_file = \"truncated_labels.csv\"\n",
        "draw_labels_on_image(image_path,labels_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "Pamd0yPYBJhm",
        "outputId": "3901a604-edf0-421b-f359-220a765b6f85"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def show_pixels(image_path,top_pixels,bot_pixels,left_pixels,right_pixels):\n",
        "    \"\"\"\n",
        "    Displays the top 20 rows of an image.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image file.\n",
        "    \"\"\"\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Check if the image was loaded correctly\n",
        "    if image is None:\n",
        "        print(f\"Error: Unable to load image at {image_path}\")\n",
        "        return\n",
        "\n",
        "    truncated_image = image[bot_pixels:top_pixels, left_pixels:right_pixels]\n",
        "\n",
        "    # Display the cropped section\n",
        "    cv2.imshow(\"img\",truncated_image)  # Use cv2_imshow in Google Colab, replace with cv2.imshow() for local use\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "extract_dir = 'extracted_captchas'\n",
        "processed_images_dir = \"processed_captchas\"\n",
        "image_path = f\"{extract_dir}/captchas_saved/captcha_315.png\"\n",
        "labels_file = \"labels.txt\"\n",
        "top_pixels,bot_pixels,left_pixels,right_pixels = 310,100,65,275 # Field coordonates\n",
        "# top_pixels,bot_pixels,left_pixels,right_pixels = 55,5,185,235 # Draw 1\n",
        "# top_pixels, bot_pixels, left_pixels, right_pixels = 50,10, 265, 305 #Draw 2\n",
        "show_pixels(image_path,top_pixels,bot_pixels,left_pixels,right_pixels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkXTRcDNEJnf",
        "outputId": "2d998411-6424-4b43-b5d6-58ca188128b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            img_name          x1          y1          x2          y2\n",
            "0      captcha_1.png   46.816017  146.209957   54.581169   18.639610\n",
            "1     captcha_10.png   54.581169  143.991342  155.528139   67.449134\n",
            "2    captcha_100.png  103.390693  192.800866   22.411255  191.691558\n",
            "3    captcha_101.png  142.216450  125.133117   60.127706  165.068182\n",
            "4    captcha_102.png   95.625541  130.679654  155.528139  170.614719\n",
            "..               ...         ...         ...         ...         ...\n",
            "311   captcha_95.png   83.423160   35.279221  122.248918  182.817100\n",
            "312   captcha_96.png   49.034632   40.825758   44.597403  172.833333\n",
            "313   captcha_97.png   45.706710  170.614719  138.888528   92.963203\n",
            "314   captcha_98.png   45.706710  105.165584  176.604978   49.700216\n",
            "315   captcha_99.png   42.378788  187.254329   23.520563  117.367965\n",
            "\n",
            "[316 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def adjust_x_coordinates(label, left_pixels):\n",
        "    return label - left_pixels\n",
        "\n",
        "def adjust_y_coordinates(label, bot_pixels):\n",
        "    return label - bot_pixels\n",
        "\n",
        "def truncate_labels(df, left_pixels = 65, bot_pixels = 100):\n",
        "    df[['x1', 'y1', 'x2', 'y2']] = df[['x1', 'y1', 'x2', 'y2']].apply(pd.to_numeric)\n",
        "    df['x1'] = df['x1'].apply(lambda x: adjust_x_coordinates(x, left_pixels))\n",
        "    df['x2'] = df['x2'].apply(lambda x: adjust_x_coordinates(x, left_pixels))\n",
        "    df['y1'] = df['y1'].apply(lambda y: adjust_y_coordinates(y, bot_pixels))\n",
        "    df['y2'] = df['y2'].apply(lambda y: adjust_y_coordinates(y, bot_pixels))\n",
        "    return df\n",
        "\n",
        "# top_pixels,bot_pixels,left_pixels,right_pixels = 310,100,65,275 # Field coordonates\n",
        "# Load the labels file\n",
        "df = pd.read_csv(\"labels.txt\")\n",
        "df.pipe(truncate_labels)\n",
        "# Save the adjusted labels\n",
        "df.to_csv('truncated_labels.csv', index=False)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZZ0f7xyI9YM",
        "outputId": "d30f2318-a07a-4fd4-b7ad-b683490af353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved cropped image: truncated_captchas\\captcha_1.png\n",
            "Saved cropped image: truncated_captchas\\captcha_10.png\n",
            "Saved cropped image: truncated_captchas\\captcha_100.png\n",
            "Saved cropped image: truncated_captchas\\captcha_101.png\n",
            "Saved cropped image: truncated_captchas\\captcha_102.png\n",
            "Saved cropped image: truncated_captchas\\captcha_103.png\n",
            "Saved cropped image: truncated_captchas\\captcha_104.png\n",
            "Saved cropped image: truncated_captchas\\captcha_105.png\n",
            "Saved cropped image: truncated_captchas\\captcha_106.png\n",
            "Saved cropped image: truncated_captchas\\captcha_107.png\n",
            "Saved cropped image: truncated_captchas\\captcha_108.png\n",
            "Saved cropped image: truncated_captchas\\captcha_109.png\n",
            "Saved cropped image: truncated_captchas\\captcha_11.png\n",
            "Saved cropped image: truncated_captchas\\captcha_110.png\n",
            "Saved cropped image: truncated_captchas\\captcha_111.png\n",
            "Saved cropped image: truncated_captchas\\captcha_112.png\n",
            "Saved cropped image: truncated_captchas\\captcha_113.png\n",
            "Saved cropped image: truncated_captchas\\captcha_114.png\n",
            "Saved cropped image: truncated_captchas\\captcha_115.png\n",
            "Saved cropped image: truncated_captchas\\captcha_116.png\n",
            "Saved cropped image: truncated_captchas\\captcha_117.png\n",
            "Saved cropped image: truncated_captchas\\captcha_118.png\n",
            "Saved cropped image: truncated_captchas\\captcha_119.png\n",
            "Saved cropped image: truncated_captchas\\captcha_12.png\n",
            "Saved cropped image: truncated_captchas\\captcha_120.png\n",
            "Saved cropped image: truncated_captchas\\captcha_121.png\n",
            "Saved cropped image: truncated_captchas\\captcha_122.png\n",
            "Saved cropped image: truncated_captchas\\captcha_123.png\n",
            "Saved cropped image: truncated_captchas\\captcha_124.png\n",
            "Saved cropped image: truncated_captchas\\captcha_125.png\n",
            "Saved cropped image: truncated_captchas\\captcha_126.png\n",
            "Saved cropped image: truncated_captchas\\captcha_127.png\n",
            "Saved cropped image: truncated_captchas\\captcha_128.png\n",
            "Saved cropped image: truncated_captchas\\captcha_129.png\n",
            "Saved cropped image: truncated_captchas\\captcha_13.png\n",
            "Saved cropped image: truncated_captchas\\captcha_130.png\n",
            "Saved cropped image: truncated_captchas\\captcha_131.png\n",
            "Saved cropped image: truncated_captchas\\captcha_132.png\n",
            "Saved cropped image: truncated_captchas\\captcha_133.png\n",
            "Saved cropped image: truncated_captchas\\captcha_134.png\n",
            "Saved cropped image: truncated_captchas\\captcha_135.png\n",
            "Saved cropped image: truncated_captchas\\captcha_136.png\n",
            "Saved cropped image: truncated_captchas\\captcha_137.png\n",
            "Saved cropped image: truncated_captchas\\captcha_138.png\n",
            "Saved cropped image: truncated_captchas\\captcha_139.png\n",
            "Saved cropped image: truncated_captchas\\captcha_14.png\n",
            "Saved cropped image: truncated_captchas\\captcha_140.png\n",
            "Saved cropped image: truncated_captchas\\captcha_141.png\n",
            "Saved cropped image: truncated_captchas\\captcha_142.png\n",
            "Saved cropped image: truncated_captchas\\captcha_143.png\n",
            "Saved cropped image: truncated_captchas\\captcha_144.png\n",
            "Saved cropped image: truncated_captchas\\captcha_145.png\n",
            "Saved cropped image: truncated_captchas\\captcha_146.png\n",
            "Saved cropped image: truncated_captchas\\captcha_147.png\n",
            "Saved cropped image: truncated_captchas\\captcha_148.png\n",
            "Saved cropped image: truncated_captchas\\captcha_149.png\n",
            "Saved cropped image: truncated_captchas\\captcha_15.png\n",
            "Saved cropped image: truncated_captchas\\captcha_150.png\n",
            "Saved cropped image: truncated_captchas\\captcha_151.png\n",
            "Saved cropped image: truncated_captchas\\captcha_152.png\n",
            "Saved cropped image: truncated_captchas\\captcha_153.png\n",
            "Saved cropped image: truncated_captchas\\captcha_154.png\n",
            "Saved cropped image: truncated_captchas\\captcha_155.png\n",
            "Saved cropped image: truncated_captchas\\captcha_156.png\n",
            "Saved cropped image: truncated_captchas\\captcha_157.png\n",
            "Saved cropped image: truncated_captchas\\captcha_158.png\n",
            "Saved cropped image: truncated_captchas\\captcha_159.png\n",
            "Saved cropped image: truncated_captchas\\captcha_16.png\n",
            "Saved cropped image: truncated_captchas\\captcha_160.png\n",
            "Saved cropped image: truncated_captchas\\captcha_161.png\n",
            "Saved cropped image: truncated_captchas\\captcha_162.png\n",
            "Saved cropped image: truncated_captchas\\captcha_163.png\n",
            "Saved cropped image: truncated_captchas\\captcha_164.png\n",
            "Saved cropped image: truncated_captchas\\captcha_165.png\n",
            "Saved cropped image: truncated_captchas\\captcha_166.png\n",
            "Saved cropped image: truncated_captchas\\captcha_167.png\n",
            "Saved cropped image: truncated_captchas\\captcha_168.png\n",
            "Saved cropped image: truncated_captchas\\captcha_169.png\n",
            "Saved cropped image: truncated_captchas\\captcha_17.png\n",
            "Saved cropped image: truncated_captchas\\captcha_170.png\n",
            "Saved cropped image: truncated_captchas\\captcha_171.png\n",
            "Saved cropped image: truncated_captchas\\captcha_172.png\n",
            "Saved cropped image: truncated_captchas\\captcha_173.png\n",
            "Saved cropped image: truncated_captchas\\captcha_174.png\n",
            "Saved cropped image: truncated_captchas\\captcha_175.png\n",
            "Saved cropped image: truncated_captchas\\captcha_176.png\n",
            "Saved cropped image: truncated_captchas\\captcha_177.png\n",
            "Saved cropped image: truncated_captchas\\captcha_178.png\n",
            "Saved cropped image: truncated_captchas\\captcha_179.png\n",
            "Saved cropped image: truncated_captchas\\captcha_18.png\n",
            "Saved cropped image: truncated_captchas\\captcha_180.png\n",
            "Saved cropped image: truncated_captchas\\captcha_181.png\n",
            "Saved cropped image: truncated_captchas\\captcha_182.png\n",
            "Saved cropped image: truncated_captchas\\captcha_183.png\n",
            "Saved cropped image: truncated_captchas\\captcha_184.png\n",
            "Saved cropped image: truncated_captchas\\captcha_185.png\n",
            "Saved cropped image: truncated_captchas\\captcha_186.png\n",
            "Saved cropped image: truncated_captchas\\captcha_187.png\n",
            "Saved cropped image: truncated_captchas\\captcha_188.png\n",
            "Saved cropped image: truncated_captchas\\captcha_189.png\n",
            "Saved cropped image: truncated_captchas\\captcha_19.png\n",
            "Saved cropped image: truncated_captchas\\captcha_190.png\n",
            "Saved cropped image: truncated_captchas\\captcha_191.png\n",
            "Saved cropped image: truncated_captchas\\captcha_192.png\n",
            "Saved cropped image: truncated_captchas\\captcha_193.png\n",
            "Saved cropped image: truncated_captchas\\captcha_194.png\n",
            "Saved cropped image: truncated_captchas\\captcha_195.png\n",
            "Saved cropped image: truncated_captchas\\captcha_196.png\n",
            "Saved cropped image: truncated_captchas\\captcha_197.png\n",
            "Saved cropped image: truncated_captchas\\captcha_198.png\n",
            "Saved cropped image: truncated_captchas\\captcha_199.png\n",
            "Saved cropped image: truncated_captchas\\captcha_2.png\n",
            "Saved cropped image: truncated_captchas\\captcha_20.png\n",
            "Saved cropped image: truncated_captchas\\captcha_200.png\n",
            "Saved cropped image: truncated_captchas\\captcha_201.png\n",
            "Saved cropped image: truncated_captchas\\captcha_202.png\n",
            "Saved cropped image: truncated_captchas\\captcha_203.png\n",
            "Saved cropped image: truncated_captchas\\captcha_204.png\n",
            "Saved cropped image: truncated_captchas\\captcha_205.png\n",
            "Saved cropped image: truncated_captchas\\captcha_206.png\n",
            "Saved cropped image: truncated_captchas\\captcha_207.png\n",
            "Saved cropped image: truncated_captchas\\captcha_208.png\n",
            "Saved cropped image: truncated_captchas\\captcha_209.png\n",
            "Saved cropped image: truncated_captchas\\captcha_21.png\n",
            "Saved cropped image: truncated_captchas\\captcha_210.png\n",
            "Saved cropped image: truncated_captchas\\captcha_211.png\n",
            "Saved cropped image: truncated_captchas\\captcha_212.png\n",
            "Saved cropped image: truncated_captchas\\captcha_213.png\n",
            "Saved cropped image: truncated_captchas\\captcha_214.png\n",
            "Saved cropped image: truncated_captchas\\captcha_215.png\n",
            "Saved cropped image: truncated_captchas\\captcha_216.png\n",
            "Saved cropped image: truncated_captchas\\captcha_217.png\n",
            "Saved cropped image: truncated_captchas\\captcha_218.png\n",
            "Saved cropped image: truncated_captchas\\captcha_219.png\n",
            "Saved cropped image: truncated_captchas\\captcha_22.png\n",
            "Saved cropped image: truncated_captchas\\captcha_220.png\n",
            "Saved cropped image: truncated_captchas\\captcha_221.png\n",
            "Saved cropped image: truncated_captchas\\captcha_222.png\n",
            "Saved cropped image: truncated_captchas\\captcha_223.png\n",
            "Saved cropped image: truncated_captchas\\captcha_224.png\n",
            "Saved cropped image: truncated_captchas\\captcha_225.png\n",
            "Saved cropped image: truncated_captchas\\captcha_226.png\n",
            "Saved cropped image: truncated_captchas\\captcha_227.png\n",
            "Saved cropped image: truncated_captchas\\captcha_228.png\n",
            "Saved cropped image: truncated_captchas\\captcha_229.png\n",
            "Saved cropped image: truncated_captchas\\captcha_23.png\n",
            "Saved cropped image: truncated_captchas\\captcha_230.png\n",
            "Saved cropped image: truncated_captchas\\captcha_231.png\n",
            "Saved cropped image: truncated_captchas\\captcha_232.png\n",
            "Saved cropped image: truncated_captchas\\captcha_233.png\n",
            "Saved cropped image: truncated_captchas\\captcha_234.png\n",
            "Saved cropped image: truncated_captchas\\captcha_235.png\n",
            "Saved cropped image: truncated_captchas\\captcha_236.png\n",
            "Saved cropped image: truncated_captchas\\captcha_237.png\n",
            "Saved cropped image: truncated_captchas\\captcha_238.png\n",
            "Saved cropped image: truncated_captchas\\captcha_239.png\n",
            "Saved cropped image: truncated_captchas\\captcha_24.png\n",
            "Saved cropped image: truncated_captchas\\captcha_240.png\n",
            "Saved cropped image: truncated_captchas\\captcha_241.png\n",
            "Saved cropped image: truncated_captchas\\captcha_242.png\n",
            "Saved cropped image: truncated_captchas\\captcha_243.png\n",
            "Saved cropped image: truncated_captchas\\captcha_244.png\n",
            "Saved cropped image: truncated_captchas\\captcha_245.png\n",
            "Saved cropped image: truncated_captchas\\captcha_246.png\n",
            "Saved cropped image: truncated_captchas\\captcha_247.png\n",
            "Saved cropped image: truncated_captchas\\captcha_248.png\n",
            "Saved cropped image: truncated_captchas\\captcha_249.png\n",
            "Saved cropped image: truncated_captchas\\captcha_25.png\n",
            "Saved cropped image: truncated_captchas\\captcha_250.png\n",
            "Saved cropped image: truncated_captchas\\captcha_251.png\n",
            "Saved cropped image: truncated_captchas\\captcha_252.png\n",
            "Saved cropped image: truncated_captchas\\captcha_253.png\n",
            "Saved cropped image: truncated_captchas\\captcha_254.png\n",
            "Saved cropped image: truncated_captchas\\captcha_255.png\n",
            "Saved cropped image: truncated_captchas\\captcha_256.png\n",
            "Saved cropped image: truncated_captchas\\captcha_257.png\n",
            "Saved cropped image: truncated_captchas\\captcha_258.png\n",
            "Saved cropped image: truncated_captchas\\captcha_259.png\n",
            "Saved cropped image: truncated_captchas\\captcha_26.png\n",
            "Saved cropped image: truncated_captchas\\captcha_260.png\n",
            "Saved cropped image: truncated_captchas\\captcha_261.png\n",
            "Saved cropped image: truncated_captchas\\captcha_262.png\n",
            "Saved cropped image: truncated_captchas\\captcha_263.png\n",
            "Saved cropped image: truncated_captchas\\captcha_264.png\n",
            "Saved cropped image: truncated_captchas\\captcha_265.png\n",
            "Saved cropped image: truncated_captchas\\captcha_266.png\n",
            "Saved cropped image: truncated_captchas\\captcha_267.png\n",
            "Saved cropped image: truncated_captchas\\captcha_268.png\n",
            "Saved cropped image: truncated_captchas\\captcha_269.png\n",
            "Saved cropped image: truncated_captchas\\captcha_27.png\n",
            "Saved cropped image: truncated_captchas\\captcha_270.png\n",
            "Saved cropped image: truncated_captchas\\captcha_271.png\n",
            "Saved cropped image: truncated_captchas\\captcha_272.png\n",
            "Saved cropped image: truncated_captchas\\captcha_273.png\n",
            "Saved cropped image: truncated_captchas\\captcha_274.png\n",
            "Saved cropped image: truncated_captchas\\captcha_275.png\n",
            "Saved cropped image: truncated_captchas\\captcha_276.png\n",
            "Saved cropped image: truncated_captchas\\captcha_277.png\n",
            "Saved cropped image: truncated_captchas\\captcha_278.png\n",
            "Saved cropped image: truncated_captchas\\captcha_279.png\n",
            "Saved cropped image: truncated_captchas\\captcha_28.png\n",
            "Saved cropped image: truncated_captchas\\captcha_280.png\n",
            "Saved cropped image: truncated_captchas\\captcha_281.png\n",
            "Saved cropped image: truncated_captchas\\captcha_282.png\n",
            "Saved cropped image: truncated_captchas\\captcha_283.png\n",
            "Saved cropped image: truncated_captchas\\captcha_284.png\n",
            "Saved cropped image: truncated_captchas\\captcha_285.png\n",
            "Saved cropped image: truncated_captchas\\captcha_286.png\n",
            "Saved cropped image: truncated_captchas\\captcha_287.png\n",
            "Saved cropped image: truncated_captchas\\captcha_288.png\n",
            "Saved cropped image: truncated_captchas\\captcha_289.png\n",
            "Saved cropped image: truncated_captchas\\captcha_29.png\n",
            "Saved cropped image: truncated_captchas\\captcha_290.png\n",
            "Saved cropped image: truncated_captchas\\captcha_291.png\n",
            "Saved cropped image: truncated_captchas\\captcha_292.png\n",
            "Saved cropped image: truncated_captchas\\captcha_293.png\n",
            "Saved cropped image: truncated_captchas\\captcha_294.png\n",
            "Saved cropped image: truncated_captchas\\captcha_295.png\n",
            "Saved cropped image: truncated_captchas\\captcha_296.png\n",
            "Saved cropped image: truncated_captchas\\captcha_297.png\n",
            "Saved cropped image: truncated_captchas\\captcha_298.png\n",
            "Saved cropped image: truncated_captchas\\captcha_299.png\n",
            "Saved cropped image: truncated_captchas\\captcha_3.png\n",
            "Saved cropped image: truncated_captchas\\captcha_30.png\n",
            "Saved cropped image: truncated_captchas\\captcha_300.png\n",
            "Saved cropped image: truncated_captchas\\captcha_301.png\n",
            "Saved cropped image: truncated_captchas\\captcha_302.png\n",
            "Saved cropped image: truncated_captchas\\captcha_303.png\n",
            "Saved cropped image: truncated_captchas\\captcha_304.png\n",
            "Saved cropped image: truncated_captchas\\captcha_305.png\n",
            "Saved cropped image: truncated_captchas\\captcha_306.png\n",
            "Saved cropped image: truncated_captchas\\captcha_307.png\n",
            "Saved cropped image: truncated_captchas\\captcha_308.png\n",
            "Saved cropped image: truncated_captchas\\captcha_309.png\n",
            "Saved cropped image: truncated_captchas\\captcha_31.png\n",
            "Saved cropped image: truncated_captchas\\captcha_310.png\n",
            "Saved cropped image: truncated_captchas\\captcha_311.png\n",
            "Saved cropped image: truncated_captchas\\captcha_312.png\n",
            "Saved cropped image: truncated_captchas\\captcha_313.png\n",
            "Saved cropped image: truncated_captchas\\captcha_314.png\n",
            "Saved cropped image: truncated_captchas\\captcha_315.png\n",
            "Saved cropped image: truncated_captchas\\captcha_316.png\n",
            "Saved cropped image: truncated_captchas\\captcha_32.png\n",
            "Saved cropped image: truncated_captchas\\captcha_33.png\n",
            "Saved cropped image: truncated_captchas\\captcha_34.png\n",
            "Saved cropped image: truncated_captchas\\captcha_35.png\n",
            "Saved cropped image: truncated_captchas\\captcha_36.png\n",
            "Saved cropped image: truncated_captchas\\captcha_37.png\n",
            "Saved cropped image: truncated_captchas\\captcha_38.png\n",
            "Saved cropped image: truncated_captchas\\captcha_39.png\n",
            "Saved cropped image: truncated_captchas\\captcha_4.png\n",
            "Saved cropped image: truncated_captchas\\captcha_40.png\n",
            "Saved cropped image: truncated_captchas\\captcha_41.png\n",
            "Saved cropped image: truncated_captchas\\captcha_42.png\n",
            "Saved cropped image: truncated_captchas\\captcha_43.png\n",
            "Saved cropped image: truncated_captchas\\captcha_44.png\n",
            "Saved cropped image: truncated_captchas\\captcha_45.png\n",
            "Saved cropped image: truncated_captchas\\captcha_46.png\n",
            "Saved cropped image: truncated_captchas\\captcha_47.png\n",
            "Saved cropped image: truncated_captchas\\captcha_48.png\n",
            "Saved cropped image: truncated_captchas\\captcha_49.png\n",
            "Saved cropped image: truncated_captchas\\captcha_5.png\n",
            "Saved cropped image: truncated_captchas\\captcha_50.png\n",
            "Saved cropped image: truncated_captchas\\captcha_51.png\n",
            "Saved cropped image: truncated_captchas\\captcha_52.png\n",
            "Saved cropped image: truncated_captchas\\captcha_53.png\n",
            "Saved cropped image: truncated_captchas\\captcha_54.png\n",
            "Saved cropped image: truncated_captchas\\captcha_55.png\n",
            "Saved cropped image: truncated_captchas\\captcha_56.png\n",
            "Saved cropped image: truncated_captchas\\captcha_57.png\n",
            "Saved cropped image: truncated_captchas\\captcha_58.png\n",
            "Saved cropped image: truncated_captchas\\captcha_59.png\n",
            "Saved cropped image: truncated_captchas\\captcha_6.png\n",
            "Saved cropped image: truncated_captchas\\captcha_60.png\n",
            "Saved cropped image: truncated_captchas\\captcha_61.png\n",
            "Saved cropped image: truncated_captchas\\captcha_62.png\n",
            "Saved cropped image: truncated_captchas\\captcha_63.png\n",
            "Saved cropped image: truncated_captchas\\captcha_64.png\n",
            "Saved cropped image: truncated_captchas\\captcha_65.png\n",
            "Saved cropped image: truncated_captchas\\captcha_66.png\n",
            "Saved cropped image: truncated_captchas\\captcha_67.png\n",
            "Saved cropped image: truncated_captchas\\captcha_68.png\n",
            "Saved cropped image: truncated_captchas\\captcha_69.png\n",
            "Saved cropped image: truncated_captchas\\captcha_7.png\n",
            "Saved cropped image: truncated_captchas\\captcha_70.png\n",
            "Saved cropped image: truncated_captchas\\captcha_71.png\n",
            "Saved cropped image: truncated_captchas\\captcha_72.png\n",
            "Saved cropped image: truncated_captchas\\captcha_73.png\n",
            "Saved cropped image: truncated_captchas\\captcha_74.png\n",
            "Saved cropped image: truncated_captchas\\captcha_75.png\n",
            "Saved cropped image: truncated_captchas\\captcha_76.png\n",
            "Saved cropped image: truncated_captchas\\captcha_77.png\n",
            "Saved cropped image: truncated_captchas\\captcha_78.png\n",
            "Saved cropped image: truncated_captchas\\captcha_79.png\n",
            "Saved cropped image: truncated_captchas\\captcha_8.png\n",
            "Saved cropped image: truncated_captchas\\captcha_80.png\n",
            "Saved cropped image: truncated_captchas\\captcha_81.png\n",
            "Saved cropped image: truncated_captchas\\captcha_82.png\n",
            "Saved cropped image: truncated_captchas\\captcha_83.png\n",
            "Saved cropped image: truncated_captchas\\captcha_84.png\n",
            "Saved cropped image: truncated_captchas\\captcha_85.png\n",
            "Saved cropped image: truncated_captchas\\captcha_86.png\n",
            "Saved cropped image: truncated_captchas\\captcha_87.png\n",
            "Saved cropped image: truncated_captchas\\captcha_88.png\n",
            "Saved cropped image: truncated_captchas\\captcha_89.png\n",
            "Saved cropped image: truncated_captchas\\captcha_9.png\n",
            "Saved cropped image: truncated_captchas\\captcha_90.png\n",
            "Saved cropped image: truncated_captchas\\captcha_91.png\n",
            "Saved cropped image: truncated_captchas\\captcha_92.png\n",
            "Saved cropped image: truncated_captchas\\captcha_93.png\n",
            "Saved cropped image: truncated_captchas\\captcha_94.png\n",
            "Saved cropped image: truncated_captchas\\captcha_95.png\n",
            "Saved cropped image: truncated_captchas\\captcha_96.png\n",
            "Saved cropped image: truncated_captchas\\captcha_97.png\n",
            "Saved cropped image: truncated_captchas\\captcha_98.png\n",
            "Saved cropped image: truncated_captchas\\captcha_99.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def crop_and_save_images(input_folder, output_folder=\"field\",top_pixels= 330, bot_pixels= 55, left_pixels= 20, right_pixels = 320):\n",
        "    \"\"\"\n",
        "    Crops images in the input_folder according to predefined pixel boundaries\n",
        "    and saves them to the output_folder with the same filenames.\n",
        "\n",
        "    Args:\n",
        "        input_folder (str): Path to the folder containing the original images.\n",
        "        output_folder (str): Path where the cropped images will be saved.\n",
        "    \"\"\"\n",
        "    # Define cropping boundaries\n",
        "    \n",
        "\n",
        "    # Create output folder if it does not exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Process each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Read the image\n",
        "        image = cv2.imread(input_path)\n",
        "        if image is None:\n",
        "            print(f\"Skipping {filename} (could not load image)\")\n",
        "            continue\n",
        "\n",
        "        # Apply cropping\n",
        "        cropped_image = image[bot_pixels:top_pixels, left_pixels:right_pixels]\n",
        "\n",
        "        # Save the cropped image to the new folder\n",
        "        cv2.imwrite(output_path, cropped_image)\n",
        "        print(f\"Saved cropped image: {output_path}\")\n",
        "\n",
        "# top_pixels,bot_pixels,left_pixels,right_pixels = 50,10,190,230 # Draw 1\n",
        "# top_pixels, bot_pixels, left_pixels, right_pixels = 50,10, 265, 305 #Draw 2\n",
        "\n",
        "# Example Usage\n",
        "top_pixels,bot_pixels,left_pixels,right_pixels = 310,100,65,275 # Field coordonates\n",
        "crop_and_save_images(\"extracted_captchas/captchas_saved\",\"truncated_captchas\",top_pixels,bot_pixels,left_pixels,right_pixels) #truncated captchas\n",
        "# top_pixels,bot_pixels,left_pixels,right_pixels = 55,5,185,235\n",
        "# crop_and_save_images(\"extracted_captchas/captchas_saved\",\"draw1\",top_pixels,bot_pixels,left_pixels,right_pixels) #Draw 1\n",
        "# top_pixels, bot_pixels, left_pixels, right_pixels = 55,5, 260, 310\n",
        "# crop_and_save_images(\"extracted_captchas/captchas_saved\",\"draw2\",top_pixels,bot_pixels,left_pixels,right_pixels) #Draw 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LuaXvUTGJGhd"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "def make_mean_image(image_folder, output_name = \"mean_image.png\"):\n",
        "    # List all image files in the folder\n",
        "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]  # Change extension if needed\n",
        "\n",
        "    # Initialize an accumulator with zeros (assuming images are the same size)\n",
        "    num_images = len(image_files)\n",
        "    if num_images == 0:\n",
        "        raise ValueError(\"No images found in the specified folder.\")\n",
        "\n",
        "    # Load the first image to get dimensions\n",
        "    first_image = cv2.imread(os.path.join(image_folder, image_files[0]), cv2.IMREAD_COLOR)\n",
        "    h, w, c = first_image.shape\n",
        "    mean_image = np.zeros((h, w, c), dtype=np.float32)\n",
        "\n",
        "    # Compute the sum of all images\n",
        "    for file in image_files:\n",
        "        img = cv2.imread(os.path.join(image_folder, file), cv2.IMREAD_COLOR)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not read {file}\")\n",
        "            continue\n",
        "        mean_image += img.astype(np.float32)  # Convert to float to prevent overflow\n",
        "\n",
        "    # Compute the mean by dividing by the number of images\n",
        "    mean_image /= num_images\n",
        "\n",
        "    # Convert back to uint8 format for visualization and saving\n",
        "    mean_image = np.clip(mean_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Save the mean image\n",
        "    cv2.imwrite(output_name, mean_image)\n",
        "\n",
        "    # Display the mean image (optional)\n",
        "    cv2.imshow(\"Mean Image\", mean_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Path to the folder containing the images\n",
        "image_folder = \"extracted_captchas/captchas_saved\"  # Change this to your actual folder path\n",
        "make_mean_image(image_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned images saved in filtered_truncated_captchas\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def retrieve_mean_image(image_folder = \"truncated_captchas\", output_folder = \"filtered_truncated_captchas\", mean_image_path = \"mean_image.png\"):\n",
        "    # Create output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Load the mean image\n",
        "    mean_image = cv2.imread(mean_image_path, cv2.IMREAD_COLOR).astype(np.float32)\n",
        "\n",
        "    # List all image files in the folder\n",
        "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]  # Change extension if needed\n",
        "\n",
        "    # Process each image\n",
        "    for file in image_files:\n",
        "        img_path = os.path.join(image_folder, file)\n",
        "        output_path = os.path.join(output_folder, file)\n",
        "        \n",
        "        # Load the image\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR).astype(np.float32)\n",
        "\n",
        "        # Subtract the mean image\n",
        "        cleaned_img = img - mean_image\n",
        "\n",
        "        # Normalize back to 0-255\n",
        "        cleaned_img = np.clip(cleaned_img, 0, 255).astype(np.uint8)\n",
        "\n",
        "        # Save the cleaned image\n",
        "        cv2.imwrite(output_path, cleaned_img)\n",
        "\n",
        "    print(f\"Cleaned images saved in {output_folder}\")\n",
        "\n",
        "# Paths\n",
        "image_folder = \"truncated_captchas\"  # Change this to your actual folder\n",
        "output_folder = \"filtered_truncated_captchas\"  # Folder to save cleaned images\n",
        "mean_image_path = \"mean_image.png\"  # Path to saved mean image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground truth coordinates: x1=40, y1=75, x2=115, y2=107\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def draw_labels_on_image(image_path, labels_file):\n",
        "    \"\"\"\n",
        "    Loads an image from image_path, retrieves ground truth (x1, y1, x2, y2) from labels.txt,\n",
        "    and displays the image with red circles at those coordinates.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the image.\n",
        "        labels_file (str): Path to the labels file (CSV or TXT with x1, y1, x2, y2).\n",
        "    \"\"\"\n",
        "    # Load the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Unable to load image: {image_path}\")\n",
        "        return\n",
        "\n",
        "    # Resize the image to (width=340, height=410) to match the model's expected size\n",
        "    image_resized = image#cv2.resize(image, (340, 410))\n",
        "\n",
        "    # Read labels from the file\n",
        "    labels_df = pd.read_csv(labels_file)  # Ensure labels.txt is formatted correctly\n",
        "    image_name = image_path.split('/')[-1]  # Extract filename from path\n",
        "\n",
        "    # Find the row corresponding to the image name (assuming there is an 'id' or filename column)\n",
        "    if 'img_name' in labels_df.columns:\n",
        "        row = labels_df[labels_df['img_name'] == image_name]\n",
        "    else:\n",
        "        row = labels_df.iloc[0]  # If there's no ID column, just use the first row (for testing)\n",
        "\n",
        "    if row.empty:\n",
        "        print(f\"No labels found for {image_name}\")\n",
        "        return\n",
        "\n",
        "    # Extract ground truth coordinates\n",
        "    x1, y1, x2, y2 = row[['x1', 'y1', 'x2', 'y2']].to_numpy().flatten()\n",
        "    x1 = int(x1)\n",
        "    x2 = int(x2)\n",
        "    y1 = int(y1)\n",
        "    y2 = int(y2)\n",
        "    print(f\"Ground truth coordinates: x1={x1}, y1={y1}, x2={x2}, y2={y2}\")\n",
        "\n",
        "    # Draw red circles at the ground truth coordinates\n",
        "    image_drawn = image_resized.copy()\n",
        "    cv2.circle(image_drawn, (x1, y1), radius=5, color=(0, 255, 0), thickness=-1)  # Green circle\n",
        "    cv2.circle(image_drawn, (x2, y2), radius=5, color=(0, 0, 255), thickness=-1)  # Red circle\n",
        "\n",
        "    # Display the image with the drawn points\n",
        "    cv2.imshow(\"img\",image_drawn)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "image_path = f\"filtered_truncated_captchas/captcha_8.png\"\n",
        "labels_file = \"truncated_labels.csv\"\n",
        "draw_labels_on_image(image_path,labels_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing mean & std: 100%|██████████| 316/316 [00:00<00:00, 1707.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "moyenne = [214.72969 217.93405 141.7747 ] \n",
            " std=[51.95303  47.542946 46.740856]\n",
            "[214.72969 217.93405 141.7747 ] [51.95303  47.542946 46.740856]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Normalizing images: 100%|██████████| 316/316 [00:00<00:00, 354.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Normalized images saved in: normalized_images\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm  # Progress bar\n",
        "\n",
        "def compute_mean_std(input_folder):\n",
        "    \"\"\"Compute the mean and std for each RGB channel across all images.\"\"\"\n",
        "    image_list = []\n",
        "    \n",
        "    for filename in tqdm(os.listdir(input_folder), desc=\"Computing mean & std\"):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        img = cv2.imread(img_path)  # Read image in BGR format\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "            image_list.append(img)\n",
        "\n",
        "    # Convert list to a big numpy array (N, H, W, C)\n",
        "    image_array = np.stack(image_list, axis=0).astype(np.float32) \n",
        "\n",
        "    # Compute mean and std along (N, H, W) axis → (C,)\n",
        "    mean = np.mean(image_array, axis=(0, 1, 2))\n",
        "    std = np.std(image_array, axis=(0, 1, 2))\n",
        "    print(f\"moyenne = {mean} \\n std={std}\")\n",
        "    return mean, std\n",
        "\n",
        "def normalize_images(input_folder, output_folder):\n",
        "    \"\"\"Normalize RGB channels of all images in input_folder and save them to output_folder.\"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)  # Create output folder if not exists\n",
        "\n",
        "    # Compute mean and std\n",
        "    mean, std = compute_mean_std(input_folder)\n",
        "    print(mean,std)\n",
        "    for filename in tqdm(os.listdir(input_folder), desc=\"Normalizing images\"):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        img = cv2.imread(img_path)  # Read image in BGR format\n",
        "        if img is None:\n",
        "            print(f\"Skipping {filename} (unable to read)\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "        img = img.astype(np.float32) \n",
        "\n",
        "        # Normalize: (pixel - mean) / std\n",
        "        img = (img - mean) / std\n",
        "\n",
        "        # Convert back to 0-255 range for saving\n",
        "        img = ((img - img.min()) / (img.max() - img.min()) * 255).astype(np.uint8)\n",
        "\n",
        "        # Save processed image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))  # Convert back to BGR\n",
        "\n",
        "    print(f\"✅ Normalized images saved in: {output_folder}\")\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "input_folder = \"truncated_captchas\"\n",
        "output_folder = \"normalized_images\"\n",
        "normalize_images(input_folder, output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing new images: 100%|██████████| 316/316 [00:00<00:00, 880.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Normalized images saved in: normalized_premier_perso\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing new images: 100%|██████████| 316/316 [00:00<00:00, 889.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Normalized images saved in: normalized_second_perso\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "def apply_existing_normalization(input_folder, output_folder, mean, std):\n",
        "    \"\"\"\n",
        "    Applies the same mean and std normalization (computed earlier) to new images.\n",
        "\n",
        "    Args:\n",
        "        input_folder (str): Path to the folder containing new images.\n",
        "        output_folder (str): Path to save the normalized images.\n",
        "        mean (tuple): Mean values of the original dataset (R, G, B).\n",
        "        std (tuple): Standard deviation values of the original dataset (R, G, B).\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
        "    df = pd.DataFrame([])\n",
        "    for filename in tqdm(os.listdir(input_folder), desc=\"Processing new images\"):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        img = cv2.imread(img_path)  # Read image in BGR format\n",
        "        if img is None:\n",
        "            print(f\"Skipping {filename} (unable to read)\")\n",
        "            continue\n",
        "        \n",
        "        # Convert to RGB and scale pixel values to [0,1]\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "\n",
        "        # Apply normalization using precomputed mean & std\n",
        "        img_normalized = (img - mean) / std  # Standardize the image\n",
        "\n",
        "        # Rescale to 0-255 for saving\n",
        "        img_normalized = ((img_normalized - img_normalized.min()) / (img_normalized.max() - img_normalized.min()) * 255).astype(np.uint8)\n",
        "        df = pd.concat([df, pd.DataFrame({\"img_name\": [filename], \"min\": [img_normalized.min()], \"max\": [img_normalized.max()]})], ignore_index=True)\n",
        "\n",
        "        # Convert back to BGR before saving (OpenCV expects BGR format)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(img_normalized, cv2.COLOR_RGB2BGR))\n",
        "    df.to_csv(input_folder+\".csv\")\n",
        "    print(f\"✅ Normalized images saved in: {output_folder}\")\n",
        "\n",
        "# Valeurs trouvées:\n",
        "mean = (0.83977205, 0.8524061, 0.55467314)  # Dataset's mean\n",
        "std = (0.2027646, 0.18541439, 0.18301369)  # Dataset's std\n",
        "\n",
        "input_folder = \"premier_perso\"\n",
        "output_folder = \"normalized_premier_perso\"\n",
        "apply_existing_normalization(input_folder, output_folder, mean, std)\n",
        "\n",
        "input_folder = \"second_perso\"\n",
        "output_folder = \"normalized_second_perso\"\n",
        "apply_existing_normalization(input_folder, output_folder, mean, std)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def encode_image(img, original_min, original_max):\n",
        "    \"\"\"\n",
        "    Reverts the min-max scaling applied to an image.\n",
        "\n",
        "    Args:\n",
        "        img (numpy.ndarray): The encoded image (after min-max scaling to 255).\n",
        "        original_min (float): The minimum pixel value before encoding.\n",
        "        original_max (float): The maximum pixel value before encoding.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The encoded image with values standardized\n",
        "    \"\"\"\n",
        "    img = img.astype(np.float32)  # Convert to float32 for precision\n",
        "\n",
        "    # Reverse min-max scaling: \n",
        "    img_encoded = img / 255.0 * (original_max - original_min) + original_min\n",
        "\n",
        "    return img_encoded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(210, 210, 3)\n",
            "(50, 50, 3)\n",
            "(50, 50, 3)\n"
          ]
        }
      ],
      "source": [
        "extract_dirs = ['normalized_images',\"normalized_premier_perso\",\"normalized_second_perso\"]\n",
        "for extract_dir in extract_dirs:\n",
        "    image_path = f\"{extract_dir}/captcha_8.png\"\n",
        "    image = cv2.imread(image_path)\n",
        "    print(image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      img_name        x1        y1        x2        y2\n",
            "0      captcha_1_rotated_1.png  0.227244  0.689850  0.264742  0.092760\n",
            "1      captcha_1_rotated_2.png  0.229355  0.702371  0.256679  0.090055\n",
            "2      captcha_1_rotated_3.png  0.223377  0.691245  0.257841  0.085348\n",
            "3      captcha_1_rotated_4.png  0.221414  0.695206  0.252786  0.089547\n",
            "4     captcha_10_rotated_1.png  0.253058  0.687196  0.746676  0.322271\n",
            "...                        ...       ...       ...       ...       ...\n",
            "1259  captcha_98_rotated_4.png  0.224242  0.494220  0.846591  0.235562\n",
            "1260  captcha_99_rotated_1.png  0.202343  0.896912  0.118106  0.559476\n",
            "1261  captcha_99_rotated_2.png  0.203476  0.895013  0.116340  0.558038\n",
            "1262  captcha_99_rotated_3.png  0.206369  0.898739  0.117417  0.554189\n",
            "1263  captcha_99_rotated_4.png  0.201659  0.888489  0.112035  0.563014\n",
            "\n",
            "[1264 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "import random\n",
        "\n",
        "def augmentation(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create augmented dataframe by adding the name of the rotated images and noise to the coordonates\n",
        "    \"\"\"\n",
        "\n",
        "    augmented_data = []  # List to collect all rows for the new dataframe\n",
        "    for _, row in df.iterrows():  # iterrows returns index and row (row is a pandas Series)\n",
        "        for i in range(1, 5):  # Iterate through 1 to 4 for the rotations\n",
        "            # Create the new img_name for each rotated image\n",
        "           \n",
        "            img_name = f'{row[\"img_name\"][:-4]}_rotated_{i}.png'\n",
        "            # Create a new row with the same coordinates but updated image name\n",
        "            new_row = {\n",
        "                df.columns[0]: img_name,\n",
        "                df.columns[1]: (row[df.columns[1]] + 3*(1/2-random.random()))/210,\n",
        "                df.columns[2]: (row[df.columns[2]] + 3*(1/2-random.random()))/210,\n",
        "                df.columns[3]: (row[df.columns[3]] + 3*(1/2-random.random()))/210,\n",
        "                df.columns[4]: (row[df.columns[4]] + 3*(1/2-random.random()))/210\n",
        "            }\n",
        "            \n",
        "            # Append the new row to the augmented_data list\n",
        "            augmented_data.append(new_row)\n",
        "\n",
        "    # Convert the list of new rows to a DataFrame\n",
        "    augmented_df = pd.DataFrame(augmented_data)\n",
        "    \n",
        "    return augmented_df\n",
        "\n",
        "\n",
        "# Load the original dataframe\n",
        "df = pd.read_csv(\"truncated_labels.csv\")\n",
        "\n",
        "# Apply augmentation to the dataframe\n",
        "augmented_df = augmentation(df)\n",
        "\n",
        "# Print the result (or save it to a CSV file)\n",
        "print(augmented_df)\n",
        "# Optionally, save the new augmented dataframe to a CSV\n",
        "augmented_df.to_csv(\"training/augmented_labels.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done !\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "#Creation of augmented data for dataset\n",
        "def rotate_image(image_path, num_rotations=4, output_dir=\"augmented_images\", rotate = True):\n",
        "    \"\"\"\n",
        "    Rotates an image 90 degrees num_rotations times and saves the result.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the original image.\n",
        "        num_rotations (int): Number of 90 degree rotations to apply.\n",
        "        output_dir (str): Directory to save the rotated images. Default is \"augmented_images\".\n",
        "    \n",
        "    Returns:\n",
        "        list: A list of file paths to the saved rotated images.\n",
        "    \"\"\"\n",
        "    # Load the image\n",
        "    img = Image.open(image_path)\n",
        "    # Prepare the output directory\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    \n",
        "    # Rotate the image the specified number of times\n",
        "    for i in range(num_rotations):\n",
        "        if rotate:\n",
        "            img = img.rotate(90, expand=True)  # Rotate 90 degrees and expand the image size if necessary\n",
        "        # Create a new file name for the rotated image\n",
        "        for j in range(1,4):\n",
        "            rotated_image_path = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(image_path))[0]}_rotated_{i+1}.png\")\n",
        "        # Save the rotated image\n",
        "        img.save(rotated_image_path)\n",
        "\n",
        "    \n",
        "def gen_datasets(norm=True):\n",
        "    if norm : \n",
        "        norm = \"normalized_\"\n",
        "    else : \n",
        "        norm = \"\"\n",
        "    image_folder = norm + \"truncated_captchas/\"\n",
        "    count = 0\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if count > 252 : break\n",
        "        count+=1\n",
        "        rotate_image(image_folder+filename,output_dir=\"training/train_set/field/\",rotate=False)\n",
        "    # image_folder = \"normalized_second_perso/\"\n",
        "    count = 0 \n",
        "    for filename in os.listdir(image_folder):\n",
        "        if count <253: \n",
        "            count+=1\n",
        "            continue\n",
        "        rotate_image(image_folder+filename,output_dir=\"training/test_set/field/\",rotate=False)\n",
        "\n",
        "    image_folder = norm + \"premier_perso/\"\n",
        "    count = 0\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if count > 252 : break\n",
        "        count+=1\n",
        "        rotate_image(image_folder+filename,output_dir=\"training/train_set/rotated_draw1/\")\n",
        "    # image_folder = \"normalized_second_perso/\"\n",
        "    count = 0 \n",
        "    for filename in os.listdir(image_folder):\n",
        "        if count <253: \n",
        "            count+=1\n",
        "            continue\n",
        "        rotate_image(image_folder+filename,output_dir=\"training/test_set/rotated_draw1/\")\n",
        "\n",
        "    image_folder = norm + \"second_perso/\"\n",
        "    count = 0\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if count > 252 : break\n",
        "        count+=1\n",
        "        rotate_image(image_folder+filename,output_dir=\"training/train_set/rotated_draw2/\")\n",
        "    # image_folder = \"normalized_second_perso/\"\n",
        "    count = 0 \n",
        "    for filename in os.listdir(image_folder):\n",
        "        if count <253: \n",
        "            count+=1\n",
        "            continue\n",
        "        rotate_image(image_folder+filename,output_dir=\"training/test_set/rotated_draw2/\")\n",
        "    print(\"Done !\")\n",
        "\n",
        "\n",
        "\n",
        "gen_datasets(norm=False)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "def save_csv_for_training(df,draw=1,train_test_split=0.8):\n",
        "    \"\"\"\n",
        "    Saves the csv containing the labels in the appropriate folder for the training and evaluating datasets\n",
        "\n",
        "    Args:\n",
        "        df (pd.Dataframe): Dataframe containing the augmented dataframe containing this columns [\"img_name\", \"x1\", \"y1\", \"x2\", \"y2\"]\n",
        "        draw (int): 1 or 2 to chose the coordonate to remove\n",
        "        train_test_split (float) : The proportion of images for the training\n",
        "    \"\"\"\n",
        "    L = [1,2]\n",
        "    df = df.drop([f\"x{L[-draw]}\",f\"y{L[-draw]}\"],axis=1)\n",
        "    df.columns = [\"img_name\",\"x\",\"y\"]\n",
        "    treshold = (int(train_test_split*len(df)/4)+1)*4 #Treshold adapted to the train_test_split\n",
        "    df[treshold:].to_csv(f\"training/test_set/rotated_draw{draw}/augmented_labels.csv\")\n",
        "    df[:treshold].to_csv(f\"training/train_set/rotated_draw{draw}/augmented_labels.csv\")\n",
        "\n",
        "# Load the original dataframe\n",
        "df = pd.read_csv(\"training/augmented_labels.csv\")\n",
        "save_csv_for_training(df,draw=1)\n",
        "save_csv_for_training(df,draw=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[1,2][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(1791.3504682222292)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.sqrt(0.0066)*210*210/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
